---
manual:WebAPI
version:0
lang:zh
rawUrl:https://developer.mozilla.org/zh-CN/docs/Web/API/AudioBufferSourceNode
---



这篇翻译不完整。请帮忙从英语[翻译这篇文章]3749 "")。






**`AudioBufferSourceNode`******接口继承自[`AudioScheduledSourceNode`]2553 "此页面仍未被本地化, 期待您的翻译!"),表现为一个音频源，它包含了一些写在内存中的音频数据，通常储存在一个ArrayBuffer对象中。在处理有严格的时间精确度要求的回放的情形下它尤其有用。比如播放那些需要满足一个指定节奏的声音或者那些储存在内存而不是硬盘或者来自网络的声音。为了播放那些有时间精确度需求但来自网络的流文件或者来自硬盘，则使用[`AudioWorkletNode`]3750 "此页面仍未被本地化, 期待您的翻译!")来实现回放。

<iframe src='https://mdn.mozillademos.org/zh-CN/docs/Web/API/AudioBufferSourceNode$samples/inheritance_diagram?revision=1360186' width='600' height='70'></iframe>


`AudioBufferSourceNode`没有输入却有一个输出，其通道数与其[`buffer`]3751 "AudioBufferSourceNode 接口的 buffer 属性提供了重复播放音频的能力，该音频使用 AudioBuffer 作为声音文件的来源。")属性所指定的`AudioBuffer`相同。如果没有设置 buffer，也就是说`buffer`属性是`null`的话，输出将包含一个无声的单通道（每个采样点均为0）。



一个[`AudioBufferSourceNode`]2543 "AudioBufferSourceNode 接口继承自")只能被播放一次，也就是说，每次调用[`start()`]3752 "此页面仍未被本地化, 期待您的翻译!")之后，如果还想再播放一遍同样的声音，那么就需要再创建一个`AudioBufferSourceNode`。庆幸的是，创建该节点的代价并不大，并且想要多次播放声音的话，实际上`AudioBuffer`也可以被重用。事实上，你可以用一种“一触即忘”的方式来使用这些节点：创建节点，调用`start()`开始播放声音，然后，你甚至不需要再保留这个节点的引用了。声音播放完成之后，垃圾收集器会找个恰当的时机回收资源。



`多次调用 AudioBufferSourceNode.stop()`是允许的。如果这时候`AudioBufferSourceNode`还没有到达缓冲区末尾的话，最近一次的调用将替换上一次的调用。



<br></br>![The AudioBufferSourceNode takes the content of an AudioBuffer and m](%3748.png "")

输入数量 | `0` 
输出数量 | `1` 
频道数量 | 由相关的[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")定义 


## 属性<a name="属性"></a>


<em>从父级的</em><em>[`AudioNode`]2549 "AudioNode 接口是一个处理音频的通用模块, 比如一个音频源 (e.g. 一个 HTML <audio> or <video> 元素), 一个音频地址或者一个中间处理模块 (e.g. 一个过滤器如 BiquadFilterNode, 或一个音量控制器如 GainNode).")继承属性</em>.

<dl><dt>[`AudioBufferSourceNode.buffer`]3751 "AudioBufferSourceNode 接口的 buffer 属性提供了重复播放音频的能力，该音频使用 AudioBuffer 作为声音文件的来源。")</dt><dd>Is an[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")that defines the audio asset to be played, or when set to the value`null`, defines a single channel of silence.</dd><dt>[`AudioBufferSourceNode.detune`]3753 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Is a[k-rate]3754 "")[`AudioParam`]2551 "下面有两种类型的 AudioParam, a-rate 和 k-rate 参数：")representing detuning of oscillation in[cents]3755 ""). Its default value is`0`.</dd><dt>[`AudioBufferSourceNode.loop`]3756 "loop属性的默认值是false")</dt><dd>Is a Boolean attribute indicating if the audio asset must be replayed when the end of the[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")is reached. Its default value is`false`.</dd><dt>[`AudioBufferSourceNode.loopStart`]3757 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Is a double value indicating, in seconds, where in the[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")the restart of the play must happen. Its default value is`0`.</dd><dt>[`AudioBufferSourceNode.loopEnd`]3758 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Is a double value indicating, in seconds, where in the[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")the replay of the play must stop (and eventually loop again). Its default value is`0`.</dd><dt>[`AudioBufferSourceNode.playbackRate`]3759 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Is an[a-rate]3760 "")[`AudioParam`]2551 "下面有两种类型的 AudioParam, a-rate 和 k-rate 参数：")that defines the speed factor at which the audio asset will be played. Since no pitch correction is applied on the output, this can be used to change the pitch of the sample.</dd></dl>
### 事件<a name="事件"></a>
<dl><dt>[`AudioBufferSourceNode.onended`]3761 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Is an[`EventHandler`]3762 "此页面仍未被本地化, 期待您的翻译!")containing the callback associated with the`[ended]3763 "/zh-CN/docs/Web/Reference/Events/ended_(Web_Audio)")`event.</dd></dl>
## 方法<a name="方法"></a>


<em>从父级的</em><em>[`AudioNode`]2549 "AudioNode 接口是一个处理音频的通用模块, 比如一个音频源 (e.g. 一个 HTML <audio> or <video> 元素), 一个音频地址或者一个中间处理模块 (e.g. 一个过滤器如 BiquadFilterNode, 或一个音量控制器如 GainNode).")继承方法</em>.

<dl><dt>[`AudioBufferSourceNode.start()`]3764 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Schedules the start of the playback of the audio asset.</dd><dt>[`AudioBufferSourceNode.stop()`]3765 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Schedules the end of the playback of an audio asset.</dd></dl>
## 例子<a name="例子"></a>


在这个例子中, 我们将会创建一个2秒的缓冲器,并用白噪音填充它, 然后通过[`AudioBufferSourceNode`]2543 "AudioBufferSourceNode 接口继承自")来播放它. 注释里说明了它的功能.



**注意**: 你可以[查看在线演示]3766 "")或[查看源代码]3767 "").



```
var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
var button = document.querySelector('button');
var pre = document.querySelector('pre');
var myScript = document.querySelector('script');

pre.innerHTML = myScript.innerHTML;

// Stereo
var channels = 2;
// Create an empty two-second stereo buffer at the
// sample rate of the AudioContext
var frameCount = audioCtx.sampleRate * 2.0;

var myArrayBuffer = audioCtx.createBuffer(2, frameCount, audioCtx.sampleRate);

button.onclick = function() {
  // Fill the buffer with white noise;
  //just random values between -1.0 and 1.0
  for (var channel = 0; channel < channels; channel++) {
   // This gives us the actual ArrayBuffer that contains the data
   var nowBuffering = myArrayBuffer.getChannelData(channel);
   for (var i = 0; i < frameCount; i++) {
     // Math.random() is in [0; 1.0]
     // audio needs to be in [-1.0; 1.0]
     nowBuffering[i] = Math.random() * 2 - 1;
   }
  }

  // Get an AudioBufferSourceNode.
  // This is the AudioNode to use when we want to play an AudioBuffer
  var source = audioCtx.createBufferSource();
  // set the buffer in the AudioBufferSourceNode
  source.buffer = myArrayBuffer;
  // connect the AudioBufferSourceNode to the
  // destination so we can hear the sound
  source.connect(audioCtx.destination);
  // start the source playing
  source.start();
}
```


**注意**: 音频数据解码的例子请查看[`AudioContext.decodeAudioData`]3730 "这是从音频轨道创建用于web audio API音频源的首选方法。")页面.



## 规范<a name="规范"></a>
Specification | Status | Comment 
[Web Audio API<br></br><small>AudioBufferSourceNode</small>]3768 "") | Working Draft |  


## 浏览器兼容性<a name="浏览器兼容性"></a>


**[We&#39;re converting our compatibility data into a machine-readable JSON format]3344 "")**. This compatibility table still uses the old format, because we haven&#39;t yet converted the data it contains.**[Find out how you can help!]3392 "")**


* 
* 
Feature | Chrome | Firefox (Gecko) | Internet Explorer | Opera | Safari (WebKit) 
Basic support | 14[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental")<sup>[1]</sup> | [23.0]3570 "Released on 2013-08-06.")(23.0) | 未实现 | 15[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental")<br></br>22 | 6[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") 
`detune`property | (Yes) | [40.0]3469 "Released on 2015-08-11.")(40.0) | 未实现 | ? | ? 






[1] As of Chrome 42.0 setting AudioBufferSourceNode.buffer more than once is deprecated. A deprecation message is displayed if the buffer attribute is assigned more than once.


## 相关页面<a name="相关页面"></a>

* [Using the Web Audio API]3743 "")



## 文档标签和贡献者
**此页面的贡献者：**[SphinxKnight]191 ""),[HuShiyuFrontEnd]3769 ""),[benber]3770 ""),[GrainBear]3771 ""),[WhiteMind]3446 ""),[Taoja]3471 "")
**最后编辑者:**[SphinxKnight]191 ""),<time>Feb 18, 2018, 8:16:54 AM</time>


