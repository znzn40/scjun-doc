---
manual:WebAPI
version:0
lang:zh
rawUrl:https://developer.mozilla.org/zh-CN/docs/Web/API/BaseAudioContext
---



这篇翻译不完整。请帮忙从英语[翻译这篇文章]4003 "")。






The`BaseAudioContext`interface acts as a base definition for online and offline audio-processing graphs, as represented by[`AudioContext`]2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")and[`OfflineAudioContext`]2971 "OfflineAudioContext 接口是一个 AudioContext 的接口，代表由多个 AudioNode 连接在一起构成的音频处理图。与 AudioContext 标准相反的是， OfflineAudioContext 不在硬件设备渲染音频；相反，它尽可能快地生成音频，输出一个 AudioBuffer 作为结果。")respectively.You wouldn&#39;t use`BaseAudioContext`directly — you&#39;d use its features via one of these two inheriting interfaces.



A`BaseAudioContext`can be a target of events, therefore it implements the[`EventTarget`]2696 "EventTarget 是一个由可以接收事件的对象实现的接口，并且可以为它们创建侦听器。")interface.

<iframe src='https://mdn.mozillademos.org/zh-CN/docs/Web/API/BaseAudioContext$samples/inheritance_diagram?revision=1353209' width='600' height='70'></iframe>
## Properties<a name="Properties"></a>
<dl><dt>[`BaseAudioContext.audioWorklet`]4004 "此页面仍未被本地化, 期待您的翻译!")<i></i>只读</dt><dd>Returns the[`AudioWorklet`]4005 "此页面仍未被本地化, 期待您的翻译!")object, used for creating custom AudioNodes with JavaScript processing.</dd><dt>[`BaseAudioContext.currentTime`]4006 "此页面仍未被本地化, 期待您的翻译!")只读</dt><dd>Returns a double representing an ever-increasing hardware time in seconds used for scheduling. It starts at`0`.</dd><dt>[`BaseAudioContext.destination`]4007 "此页面仍未被本地化, 期待您的翻译!")只读</dt><dd>Returns an[`AudioDestinationNode`]2547 "AudioDestinationNode可以通过AudioContext.destination属性来查看。")representing the final destination of all audio in the context. It can be thought of as the audio-rendering device.</dd><dt>[`BaseAudioContext.listener`]4008 "此页面仍未被本地化, 期待您的翻译!")只读</dt><dd>Returns the[`AudioListener`]2548 "此页面仍未被本地化, 期待您的翻译!")object, used for 3D spatialization.</dd><dt>[`BaseAudioContext.sampleRate`]4009 "此页面仍未被本地化, 期待您的翻译!")只读</dt><dd>Returns a float representing the sample rate (in samples per second) used by all nodes in this context. The sample-rate of an[`AudioContext`]2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")cannot be changed.</dd><dt>[`BaseAudioContext.state`]4010 "此页面仍未被本地化, 期待您的翻译!")只读</dt><dd>Returns the current state of the`AudioContext`.</dd></dl>
### Event handlers<a name="Event_handlers"></a>
<dl><dt>[`BaseAudioContext.onstatechange`]4011 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>An event handler that runs when an event of type`[statechange]3779 "/zh-CN/docs/Web/Reference/Events/statechange")`has fired. This occurs when the`AudioContext`&#39;s state changes, due to the calling of one of the state change methods ([`AudioContext.suspend`]3780 "AudioContext 接口的suspend() 方法suspends the progression of time in the audio context, temporarily halting audio hardware access and reducing CPU/battery usage in the process — this is useful if you want an application to power down the audio hardware when it will not be using an audio context for a while."),[`AudioContext.resume`]3781 "AudioContext 的 resume() 方法，恢复之前暂停播放的音频。"), or[`AudioContext.close`]3782 "AudioContext的close()方法可以关闭audio context，同时释放占用的所有系统资源。")).</dd></dl>
## Methods<a name="Methods"></a>


<em>Also implements methods from the interface</em>[`EventTarget`]2696 "EventTarget 是一个由可以接收事件的对象实现的接口，并且可以为它们创建侦听器。").

<dl><dt>[`BaseAudioContext.createBuffer()`]4012 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a new, empty[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")object, which can then be populated by data and played via an[`AudioBufferSourceNode`]2543 "AudioBufferSourceNode 接口继承自").</dd><dt>[`BaseAudioContext.createConstantSource()`]4013 " createConstantSource() 是 BaseAudioContext 接口的一个方法， 用于生成一个 ConstantSourceNode 对象, 该对象是一个输出单信道（one-channel）音频信号的音频源，这些音频信号都拥有一个恒定的样本值。")</dt><dd>Creates a[`ConstantSourceNode`]2619 "此页面仍未被本地化, 期待您的翻译!")object, which is an audio source that continuously outputs a monaural (one-channel) sound signal whose samples all have the same value.</dd><dt>[`BaseAudioContext.createBufferSource()`]4014 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates an[`AudioBufferSourceNode`]2543 "AudioBufferSourceNode 接口继承自"), which can be used to play and manipulate audio data contained within an[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")object.[`AudioBuffer`]2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")s are created using[`AudioContext.createBuffer`]3731 "音频环境AudioContext 接口的 createBuffer() 方法用于新建一个空白的 AudioBuffer 对象，以便用于填充数据，通过 AudioBufferSourceNode 播放。")or returned by[`AudioContext.decodeAudioData`]3730 "这是从音频轨道创建用于web audio API音频源的首选方法。")when it successfully decodes an audio track.</dd><dt>[`BaseAudioContext.createScriptProcessor()`]4015 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`ScriptProcessorNode`]3198 ""), which can be used for direct audio processing via JavaScript.</dd><dt>[`BaseAudioContext.createStereoPanner()`]4016 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`StereoPannerNode`]3227 "此页面仍未被本地化, 期待您的翻译!"), which can be used to apply stereo panning to an audio source.</dd><dt>[`BaseAudioContext.createAnalyser()`]4017 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates an[`AnalyserNode`]2531 "AnalyserNode 赋予了节点可以提供实时频率及时间域分析的信息。它使一个 AudioNode 通过音频流不做修改的从输入到输出, 但允许你获取生成的数据, 处理它并创建音频可视化."), which can be used to expose audio time and frequency data and for example to create data visualisations.</dd><dt>[`BaseAudioContext.createBiquadFilter()`]4018 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`BiquadFilterNode`]2563 "BiquadFilterNode接口表示一个简单低阶滤波器(双二阶滤波器), 通过 AudioContext.createBiquadFilter() 方法创建. 它是一个能表示不同类型的过滤器，声调控制设备，图形均衡器的AudioNode ."), which represents a second order filter configurable as several different common filter types: high-pass, low-pass, band-pass, etc.</dd><dt>[`BaseAudioContext.createChannelMerger()`]4019 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`ChannelMergerNode`]2606 "此页面仍未被本地化, 期待您的翻译!"), which is used to combine channels from multiple audio streams into a single audio stream.</dd><dt>[`BaseAudioContext.createChannelSplitter()`]4020 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`ChannelSplitterNode`]2607 "此页面仍未被本地化, 期待您的翻译!"), which is used to access the individual channels of an audio stream and process them separately.</dd><dt>[`BaseAudioContext.createConvolver()`]4021 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`ConvolverNode`]2624 "此页面仍未被本地化, 期待您的翻译!"), which can be used to apply convolution effects to your audio graph, for example a reverberation effect.</dd><dt>[`BaseAudioContext.createDelay()`]4022 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`DelayNode`]2661 "此页面仍未被本地化, 期待您的翻译!"), which is used to delay the incoming audio signal by a certain amount. This node is also useful to create feedback loops in a Web Audio API graph.</dd><dt>[`BaseAudioContext.createDynamicsCompressor()`]4023 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`DynamicsCompressorNode`]2678 "此页面仍未被本地化, 期待您的翻译!"), which can be used to apply acoustic compression to an audio signal.</dd><dt>[`BaseAudioContext.createGain()`]4024 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`GainNode`]2721 "增益是一个无单位量，会对所有输入声道的音频进行相应的增加。当对 GainNode 进行修改时，新的增益会通过 de-zippering 算法进行应用，以防止出现“咔嗒”的奇怪声响。"), which can be used to control the overall volume of the audio graph.</dd><dt>[`BaseAudioContext.createIIRFilter()`]4025 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates an[`IIRFilterNode`]2834 "此页面仍未被本地化, 期待您的翻译!"), which represents a second order filter configurable as several different common filter types.</dd><dt>[`BaseAudioContext.createOscillator()`]4026 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates an[`OscillatorNode`]2975 "OscillatorNode 接口表示一个周期的波形，比如一个正弦波. 它是一个 AudioScheduledSourceNode 音频处理模块， 这个模块会对一个指定频率将创建的给定波产生影响, 一个恒定的音调."), a source representing a periodic waveform. It basically generates a tone.</dd><dt>[`BaseAudioContext.createPanner()`]4027 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`PannerNode`]2977 "此页面仍未被本地化, 期待您的翻译!"), which is used to spatialise an incoming audio stream in 3D space.</dd><dt>[`BaseAudioContext.createPeriodicWave()`]4028 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`PeriodicWave`]3001 "此页面仍未被本地化, 期待您的翻译!"), used to define a periodic waveform that can be used to determine the output of an[`OscillatorNode`]2975 "OscillatorNode 接口表示一个周期的波形，比如一个正弦波. 它是一个 AudioScheduledSourceNode 音频处理模块， 这个模块会对一个指定频率将创建的给定波产生影响, 一个恒定的音调.").</dd><dt>[`BaseAudioContext.createWaveShaper()`]4029 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Creates a[`WaveShaperNode`]3289 "此页面仍未被本地化, 期待您的翻译!"), which is used to implement non-linear distortion effects.</dd><dt>[`BaseAudioContext.decodeAudioData()`]4030 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Asynchronously decodes audio file data contained in an[`ArrayBuffer`]3805 "此页面仍未被本地化, 期待您的翻译!"). In this case, the ArrayBuffer is usually loaded from an[`XMLHttpRequest`]3324 "XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。")&#39;s`response`attribute after setting the`responseType`to`arraybuffer`. This method only works on complete files, not fragments of audio files.</dd><dt>[`BaseAudioContext.resume()`]4031 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>Resumes the progression of time in an audio context that has previously been suspended/paused.</dd></dl>
## Examples<a name="Examples"></a>


Basic audio context declaration:


```
var audioCtx = new AudioContext();
```


Cross browser variant:


```
var AudioContext = window.AudioContext || window.webkitAudioContext;
var audioCtx = new AudioContext();

var oscillatorNode = audioCtx.createOscillator();
var gainNode = audioCtx.createGain();
var finish = audioCtx.destination;
// etc.
```

## Specifications<a name="Specifications"></a>
Specification | Status | Comment 
[Web Audio API<br></br><small>BaseAudioContext</small>]4032 "") | Working Draft |  


## Browser compatibility<a name="Browser_compatibility"></a>


**[We&#39;re converting our compatibility data into a machine-readable JSON format]3344 "")**. This compatibility table still uses the old format, because we haven&#39;t yet converted the data it contains.**[Find out how you can help!]3392 "")**


* 
* 
Feature | Chrome | Edge | Firefox (Gecko) | Internet Explorer | Opera | Safari (WebKit) 
Basic support | (Yes) | (Yes) | (Yes) | 未实现 | 15.0[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental")<br></br>22 | 6.0[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") 
`baseLatency` | 60 | ? | ? | ? | ? | ? 
`createConstantSource()` | 56 | 未实现 | [52]4033 "Released on 2017-03-07.")(52) | 未实现 | 43 | 未实现 
`createStereoPanner()` | 42 | (Yes) | [37.0]4034 "Released on 2015-04-07.")(37.0) | 未实现 | 未实现 | 未实现 
`onstatechange`,`state`,`suspend()`,`resume()` | (Yes) | (Yes) | [40.0]3469 "Released on 2015-08-11.")(40.0) | 未实现 | 未实现 | 8.0 
Unprefixed | (Yes) | (Yes) |  |  |  |  





## See also<a name="See_also"></a>

* [Using the Web Audio API]3811 "")
* [`AudioContext`]2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")
* [`OfflineAudioContext`]2971 "OfflineAudioContext 接口是一个 AudioContext 的接口，代表由多个 AudioNode 连接在一起构成的音频处理图。与 AudioContext 标准相反的是， OfflineAudioContext 不在硬件设备渲染音频；相反，它尽可能快地生成音频，输出一个 AudioBuffer 作为结果。")



## 文档标签和贡献者
**标签：**
* [API]50 "")
* [Audio]3822 "")
* [BaseAudioContext]4035 "")
* [Interface]3380 "")
* [NeedsTranslation]4036 "")
* [Reference]3381 "")
* [TopicStub]4037 "")
* [Web Audio API]3830 "")

**此页面的贡献者：**[Jedipedia]4038 "")
**最后编辑者:**[Jedipedia]4038 ""),<time>Dec 18, 2017, 4:02:14 AM</time>


