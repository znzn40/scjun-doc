---
manual:WebAPI
version:0
lang:zh
rawUrl:https://developer.mozilla.org/zh-CN/docs/Web/API/OfflineAudioContext
---





`OfflineAudioContext`接口是一个[`AudioContext`](%2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")的接口，代表由多个[`AudioNode`](%2549 "AudioNode 接口是一个处理音频的通用模块, 比如一个音频源 (e.g. 一个 HTML <audio> or <video> 元素), 一个音频地址或者一个中间处理模块 (e.g. 一个过滤器如 BiquadFilterNode, 或一个音量控制器如 GainNode).")连接在一起构成的音频处理图。与[`AudioContext`](%2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")标准相反的是，`OfflineAudioContext`不在硬件设备渲染音频；相反，它尽可能快地生成音频，输出一个[`AudioBuffer`](%2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")作为结果。


## 构造函数<a name="构造函数"></a>
<dl><dt>[`OfflineAudioContext.OfflineAudioContext()`](%15785 "OfflineAudioContext() 构造函数创建一个新的 OfflineAudioContext 对象实例。")</dt><dd>创建一个新的`OfflineAudioContext`实例。</dd></dl>
## 属性<a name="属性"></a>


<em>从父级[`AudioContext`](%2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")获取属性。</em>

<dl><dt>[`OfflineAudioContext.length`](%15786 "OfflineAudioContext 接口的 length 属性返回一个代表采样帧的缓冲区大小的整数。")只读</dt><dd>代表采样帧缓冲区大小的整数。</dd></dl>
### 事件处理程序<a name="事件处理程序"></a>
<dl><dt>[`OfflineAudioContext.oncomplete`](%15787 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>当进程完成时，基于事件版本的[`OfflineAudioContext.startRendering()`](%15788 "此页面仍未被本地化, 期待您的翻译!")被使用之后，[`EventHandler`](%3762 "此页面仍未被本地化, 期待您的翻译!")将会被调用，`[complete](%14550 "/zh-CN/docs/Web/Reference/Events/complete")`事件类型为[`OfflineAudioCompletionEvent`](%2970 "此页面仍未被本地化, 期待您的翻译!")）被触发。</dd></dl>
## 方法<a name="方法"></a>


<em>从父级[`AudioContext`](%2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")和[`EventTarget`](%2696 "EventTarget 是一个由可以接收事件的对象实现的接口，并且可以为它们创建侦听器。")获取方法的实现。</em>

<dl><dt>[`OfflineAudioContext.resume()`](%15789 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>恢复一个被暂停的音频的时间进程。</dd><dt>[`OfflineAudioContext.suspend()`](%15790 "The suspend() method of the OfflineAudioContext interface schedules a suspension of the time progression in the audio context at the specified time and returns a promise. This is generally useful at the time of manipulating the audio graph synchronously on OfflineAudioContext.")</dt><dd>在指定的时间安排音频暂停时间进程，并且通过 Promise 返回。</dd><dt>[`OfflineAudioContext.startRendering()`](%15788 "此页面仍未被本地化, 期待您的翻译!")</dt><dd>开始渲染音频，考虑当前连接和当前计划的修改。这个页面涵盖基于事件的和基于 Promise 的版本。</dd></dl>
## 例子<a name="例子"></a>


这个简单的例子中，我们声明了[`AudioContext`](%2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")和`OfflineAudioContext`对象。我们使用`AudioContext`去加载一个 XHR （[`AudioContext.decodeAudioData`](%3730 "这是从音频轨道创建用于web audio API音频源的首选方法。")）获取的音轨，然后使用`OfflineAudioContext`去渲染音频并得到一个 into an[`AudioBufferSourceNode`](%2543 "AudioBufferSourceNode 接口继承自,表现为一个音频源，它包含了一些写在内存中的音频数据，通常储存在一个ArrayBuffer对象中。在处理有严格的时间精确度要求的回放的情形下它尤其有用。比如播放那些需要满足一个指定节奏的声音或者那些储存在内存而不是硬盘或者来自网络的声音。为了播放那些有时间精确度需求但来自网络的流文件或者来自硬盘，则使用")，并播放这个音轨。在离线音频处理图建立后，你需要去使用[`OfflineAudioContext.startRendering`](%15788 "此页面仍未被本地化, 期待您的翻译!")来渲染它成为[`AudioBuffer`](%2542 "这些类型对象被设计来控制小音频片段，往往短于45秒。对于更长的声音，通过 MediaElementAudioSourceNode来实现更为合适。缓存区（buffer）包含以下数据：不间断的IEEE75432位线性PCM，从-1到1的范围额定，就是说，32位的浮点缓存区的每个样本在-1.0到1.0之间。如果AudioBuffer有不同的频道，他们通常被保存在独立的缓存区。")。



当`startRendering()`的 Promise 解决后，渲染也完成了，在 Promise 内可以获得输出的`AudioBuffer。`



在此刻，我们创建了一个另外的音频上下文，在它里面创建了一个[`AudioBufferSourceNode`](%2543 "AudioBufferSourceNode 接口继承自,表现为一个音频源，它包含了一些写在内存中的音频数据，通常储存在一个ArrayBuffer对象中。在处理有严格的时间精确度要求的回放的情形下它尤其有用。比如播放那些需要满足一个指定节奏的声音或者那些储存在内存而不是硬盘或者来自网络的声音。为了播放那些有时间精确度需求但来自网络的流文件或者来自硬盘，则使用")，并且设置它的 buffer 为之前生成的 Promise 中的`AudioBuffer。这样它就可以作为简单标准音频图来播放了`。



**注意**: 为了获取可以运行的例子，请看我们在 Github 的仓库[offline-audio-context-promise](%15791 "")（也可以看到[源代码](%15792 "")。）



```
// 定义一个在线或者离线的音频上下文

var audioCtx = new AudioContext();
var offlineCtx = new OfflineAudioContext(2,44100*40,44100);

source = offlineCtx.createBufferSource();

// 使用 XHR 去加载一个音轨，
// 使用 decodeAudioData 去解码，
// 使用 OfflineAudioContext 去渲染它

function getData() {
  request = new XMLHttpRequest();

  request.open('GET', 'viper.ogg', true);

  request.responseType = 'arraybuffer';

  request.onload = function() {
    var audioData = request.response;

    audioCtx.decodeAudioData(audioData, function(buffer) {
      myBuffer = buffer;
      source.buffer = myBuffer;
      source.connect(offlineCtx.destination);
      source.start();
      //source.loop = true;
      offlineCtx.startRendering().then(function(renderedBuffer) {
        console.log('渲染完全成功');
        var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        var song = audioCtx.createBufferSource();
        song.buffer = renderedBuffer;

        song.connect(audioCtx.destination);

        play.onclick = function() {
          song.start();
        }
      }).catch(function(err) {
          console.log('渲染失败: ' + err);
          // 注意: 当 OfflineAudioContext 上 startRendering 被立刻调用，Promise 应该被 reject
      });
    });
  }

  request.send();
}

// 运行 getData 去开始这个进程

getData();
```

## 备注<a name="备注"></a>
Specification | Status | Comment 
[Web Audio API<br></br><small>OfflineAudioContext</small>](%15793 "") | Working Draft | Initial definition 


## 浏览器兼容性<a name="浏览器兼容性"></a>


**[We&#39;re converting our compatibility data into a machine-readable JSON format](%3344 "")**. This compatibility table still uses the old format, because we haven&#39;t yet converted the data it contains.**[Find out how you can help!](%3392 "")**


* 
* 
Feature | Chrome | Edge | Firefox (Gecko) | Internet Explorer | Opera | Safari (WebKit) 
Basic support | 10.0[webkit](%3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") | (Yes) | [25.0](%3679 "Released on 2013-10-29.")(25.0) | 未实现 | 15.0[webkit](%3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental")<br></br>22 (unprefixed) | 6.0[webkit](%3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") 
Promise-based`startRendering()` | 42.0 | ? | [37.0](%4034 "Released on 2015-04-07.")(37.0) | ? | ? | ? 
`suspend()`,`resume()` | 49.0 | ? |  |  |  |  
`length` | 51.0 | ? |  |  |  |  





## 参见<a name="参见"></a>

* [Web Audio API 的运用](%14975 "")



## 文档标签和贡献者
**此页面的贡献者：**[micblo](%3936 "")
**最后编辑者:**[micblo](%3936 ""),<time>Apr 15, 2017, 8:52:43 PM</time>


