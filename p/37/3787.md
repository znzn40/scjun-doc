---
manual:WebAPI
version:0
lang:zh
rawUrl:https://developer.mozilla.org/zh-CN/docs/Web/API/AudioContext/createMediaStreamDestination
---



这篇翻译不完整。请帮忙从英语[翻译这篇文章](%22901 "")。






[`AudioContext`](%2544 "AudioContext接口表示由音频模块连接而成的音频处理图，每个模块对应一个AudioNode。AudioContext可以控制它所包含的节点的创建，以及音频处理、解码操作的执行。做任何事情之前都要先创建AudioContext对象，因为一切都发生在这个环境之中。")接口的`createMediaStreamDestination()方法用于创建一个新的对象，该对象关联着表示音频流的一个`[WebRTC](%14668 "")[`MediaStream`](%2894 "MediaStream 接口是一个媒体内容的流.。一个流包含几个轨道，比如视频和音频轨道。"),音频流可以存储在本地文件或者被发送到另外一台计算机.




The[`MediaStream`](%2894 "MediaStream 接口是一个媒体内容的流.。一个流包含几个轨道，比如视频和音频轨道。")is created when the node is created and is accessible via the[`MediaStreamAudioDestinationNode`](%2895 "此页面仍未被本地化, 期待您的翻译!")&#39;s`strea<dfn>m</dfn>`attribute. This stream can be used in a similar way as a`MediaStream`obtained via[`navigator.getUserMedia`](%14971 "Navigator.getUserMedia()方法提醒用户需要使用音频（0或者1）和（0或者1）视频输入设备，比如相机，屏幕共享，或者麦克风。如果用户给予许可，successCallback回调就会被调用，MediaStream对象作为回调函数的参数。如果用户拒绝许可或者没有媒体可用，errorCallback就会被调用，类似的，PermissionDeniedError 或者NotFoundError对象作为它的参数。注意，有可能以上两个回调函数都不被调用，因为不要求用户一定作出选择（允许或者拒绝）。")— it can, for example, be sent to a remote peer using the`RTCPeerConnection``addStream()`method.



For more details about media stream destination nodes, check out the[`MediaStreamAudioDestinationNode`](%2895 "此页面仍未被本地化, 期待您的翻译!")reference page.


## 语法<a name="语法"></a>

```
var audioCtx = new AudioContext();
var destination = audioCtx.createMediaStreamDestination();
```

### 返回值<a name="返回值"></a>


A[`MediaStreamAudioDestinationNode`](%2895 "此页面仍未被本地化, 期待您的翻译!").


## Example<a name="Example"></a>


In the following simple example, we create a[`MediaStreamAudioDestinationNode`](%2895 "此页面仍未被本地化, 期待您的翻译!"), an[`OscillatorNode`](%2975 "OscillatorNode 接口表示一个周期的波形，比如一个正弦波. 它是一个 AudioScheduledSourceNode 音频处理模块， 这个模块会对一个指定频率将创建的给定波产生影响, 一个恒定的音调.")and a[`MediaRecorder`](%2889 "MediaRecorder 是 MediaStream Recording API 提供的用来进行媒体轻松录制的接口, 他需要通过调用 MediaRecorder() 构造方法进行实例化.")(the example will therefore only work in Firefox at this time.) The`MediaRecorder`is set up to record information from the`MediaStreamDestinationNode`.



When the button is clicked, the oscillator starts, and the`MediaRecorder`is started. When the button is stopped, the oscillator and`MediaRecorder`both stop. Stopping the`MediaRecorder`causes the`dataavailable`event to fire, and the event data is pushed into the`chunks`array. After that, the`stop`event fires, a new`blob`is made of type opus — which contains the data in the`chunks`array, and a new window (tab) is then opened that points to a URL created from the blob.



From here, you can play and save the opus file.


```
<!DOCTYPE html>
<html>
  <head>
    <title>createMediaStreamDestination() demo</title>
  </head>
  <body>
    <h1>createMediaStreamDestination() demo</h1>

    <p>Encoding a pure sine wave to an Opus file </p>
    <button>Make sine wave</button>
    <audio controls></audio>
    <script>
     var b = document.querySelector("button");
     var clicked = false;
     var chunks = [];
     var ac = new AudioContext();
     var osc = ac.createOscillator();
     var dest = ac.createMediaStreamDestination();
     var mediaRecorder = new MediaRecorder(dest.stream);
     osc.connect(dest);

     b.addEventListener("click", function(e) {
       if (!clicked) {
           mediaRecorder.start();
           osc.start(0);
           e.target.innerHTML = "Stop recording";
           clicked = true;
         } else {
           mediaRecorder.stop();
           osc.stop(0);
           e.target.disabled = true;
         }
     });

     mediaRecorder.ondataavailable = function(evt) {
       // push each chunk (blobs) in an array
       chunks.push(evt.data);
     };

     mediaRecorder.onstop = function(evt) {
       // Make blob out of our blobs, and open it.
       var blob = new Blob(chunks, { 'type' : 'audio/ogg; codecs=opus' });
       document.querySelector("audio").src = URL.createObjectURL(blob);
     };
    </script>
  </body>
</html> 

```


**Note**: You can[view this example live](%14962 ""), or[study the source code](%14963 ""), on Github.



## Specifications<a name="Specifications"></a>
Specification | Status | Comment 
[Web Audio API<br></br><small>createMediaStreamDestination()</small>](%22902 "") | Working Draft |  


## Browser compatibility<a name="Browser_compatibility"></a>


**[We&#39;re converting our compatibility data into a machine-readable JSON format](%3344 "")**. This compatibility table still uses the old format, because we haven&#39;t yet converted the data it contains.**[Find out how you can help!](%3392 "")**


* 
* 
Feature | Chrome | Firefox (Gecko) | Internet Explorer | Opera | Safari (WebKit) 
Basic support | 10.0[webkit](%3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") | [25.0](%3679 "Released on 2013-10-29.")(25.0) | 未实现 | 15.0[webkit](%3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental")<br></br>22 (unprefixed) | 6.0[webkit](%3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") 





## See also<a name="See_also"></a>

* [Using the Web Audio API](%3811 "")



## 文档标签和贡献者
**此页面的贡献者：**[huangxok](%3914 "")
**最后编辑者:**[huangxok](%3914 ""),<time>May 16, 2017, 6:46:56 PM</time>


