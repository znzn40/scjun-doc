---
manual:WebAPI
version:0
lang:zh
rawUrl:https://developer.mozilla.org/zh-CN/docs/Web/API/MediaStreamAudioSourceNode
---





`MediaStreamAudioSourceNode`接口代表一个音频接口，是[WebRTC]14668 "/en-US/docs/WebRTC")[`MediaStream`]2894 "MediaStream 接口是一个媒体内容的流.。一个流包含几个轨道，比如视频和音频轨道。")(比如一个摄像头或者麦克风)的一部分。是个表现为音频源的[`AudioNode`]2549 "AudioNode 接口是一个处理音频的通用模块, 比如一个音频源 (e.g. 一个 HTML <audio> or <video> 元素), 一个音频地址或者一个中间处理模块 (e.g. 一个过滤器如 BiquadFilterNode, 或一个音量控制器如 GainNode).")。




`MediaElementSourceNode没有输入，并且只有一个输出。创建之后使用`[`AudioContext.createMediaStreamSource`]3786 "更多关于媒体流音频源(media stream audio source nodes)的细节, 请参考MediaStreamAudioSourceNode 页面.")方法。输出通道的数量和[`AudioMediaStreamTrack`]14969 "此页面仍未被本地化, 期待您的翻译!")的通道数量相同。如果没有有效的媒体流，输出通道就变成一个静音的通道。

Number of inputs | `0` 
Number of outputs | `1` 
Channel count | 由[`AudioMediaStreamTrack`]14969 "此页面仍未被本地化, 期待您的翻译!")定义，传递给[`AudioContext.createMediaStreamSource`]3786 "更多关于媒体流音频源(media stream audio source nodes)的细节, 请参考MediaStreamAudioSourceNode 页面.")，并由此创建。 


## 构造器<a name="构造器"></a>
<dl><dt>[`MediaStreamAudioSourceNode.MediaStreamAudioSourceNode()`]14970 "MediaStreamAudioSourceNode()构造器创建一个新的 MediaStreamAudioSourceNode对象实例。")</dt><dd>创建一个新的`MediaStreamAudioSourceNode`实例。</dd></dl>
## 属性<a name="属性"></a>


<em>从</em><em>[`AudioNode`]2549 "AudioNode 接口是一个处理音频的通用模块, 比如一个音频源 (e.g. 一个 HTML <audio> or <video> 元素), 一个音频地址或者一个中间处理模块 (e.g. 一个过滤器如 BiquadFilterNode, 或一个音量控制器如 GainNode).")上继承。</em>


## 方法<a name="方法"></a>


<em>从</em><em>[`AudioNode`]2549 "AudioNode 接口是一个处理音频的通用模块, 比如一个音频源 (e.g. 一个 HTML <audio> or <video> 元素), 一个音频地址或者一个中间处理模块 (e.g. 一个过滤器如 BiquadFilterNode, 或一个音量控制器如 GainNode).")上继承。</em>


## 示例<a name="示例"></a>


本例中，我们从[`navigator.getUserMedia`]14971 "Navigator.getUserMedia()方法提醒用户需要使用音频（0或者1）和（0或者1）视频输入设备，比如相机，屏幕共享，或者麦克风。如果用户给予许可，successCallback回调就会被调用，MediaStream对象作为回调函数的参数。如果用户拒绝许可或者没有媒体可用，errorCallback就会被调用，类似的，PermissionDeniedError 或者NotFoundError对象作为它的参数。注意，有可能以上两个回调函数都不被调用，因为不要求用户一定作出选择（允许或者拒绝）。")获取媒体 (audio + video) 流,，把它传入[`<video>`]30 "HTML <video> 元素 用于在HTML或者XHTML文档中嵌入视频内容。")中播放，并把视频调成静音，然后把获取到的audio传入[`MediaStreamAudioSourceNode`]2896 "MediaElementSourceNode没有输入，并且只有一个输出。创建之后使用 AudioContext.createMediaStreamSource方法。输出通道的数量和AudioMediaStreamTrack的通道数量相同。如果没有有效的媒体流，输出通道就变成一个静音的通道。")。接下来我们把获取到的audio传入[`BiquadFilterNode`]2563 "BiquadFilterNode接口表示一个简单低阶滤波器(双二阶滤波器), 通过 AudioContext.createBiquadFilter() 方法创建. 它是一个能表示不同类型的过滤器，声调控制设备，图形均衡器的AudioNode .")(可以把声音转化为低音)，输出到[`AudioDestinationNode`]2547 "AudioDestinationNode可以通过AudioContext.destination属性来查看。").



[`<video>`]30 "HTML <video> 元素 用于在HTML或者XHTML文档中嵌入视频内容。")元素下面滑动杆控制低音过滤器过滤的程度，滑动杆的值越大，低音更明显



**注意：你可以查看**[在线演示]14972 "")，或者[查看源码]14973 "")。



```
var pre = document.querySelector('pre');
var video = document.querySelector('video');
var myScript = document.querySelector('script');
var range = document.querySelector('input');

// getUserMedia获取流
// 把流放入MediaStreamAudioSourceNode
// 输出到video元素

if (navigator.mediaDevices) {
    console.log('getUserMedia supported.');
    navigator.mediaDevices.getUserMedia ({audio: true, video: true})
    .then(function(stream) {
        video.srcObject = stream;
        video.onloadedmetadata = function(e) {
            video.play();
            video.muted = true;
        };

        // 创建MediaStreamAudioSourceNode
        // Feed the HTMLMediaElement into it
        var audioCtx = new AudioContext();
        var source = audioCtx.createMediaStreamSource(stream);

        // 创建二阶滤波器
        var biquadFilter = audioCtx.createBiquadFilter();
        biquadFilter.type = "lowshelf";
        biquadFilter.frequency.value = 1000;
        biquadFilter.gain.value = range.value;

        // 把AudioBufferSourceNode连接到gainNode
        // gainNode连接到目的地, 所以我们可以播放
        // 音乐并用鼠标调节音量
        source.connect(biquadFilter);
        biquadFilter.connect(audioCtx.destination);

        // Get new mouse pointer coordinates when mouse is moved
        // then set new gain value

        range.oninput = function() {
            biquadFilter.gain.value = range.value;
        }
    })
    .catch(function(err) {
        console.log('The following gUM error occured: ' + err);
    });
} else {
   console.log('getUserMedia not supported on your browser!');
}

// dump script to pre element

pre.innerHTML = myScript.innerHTML; 

```


**注意**: 调用`createMediaStreamSource()`, 来自于媒体流的音频回放将被重新传到AudioContext的处理器中。所以播放/暂停流仍然是可以通过media元素的API和自带的控制器控制。







## 规范<a name="规范"></a>
Specification | Status | Comment 
[Web Audio API<br></br><small>MediaStreamAudioSourceNode</small>]14974 "") | Working Draft |  


## 兼容性<a name="兼容性"></a>


**[We&#39;re converting our compatibility data into a machine-readable JSON format]3344 "")**. This compatibility table still uses the old format, because we haven&#39;t yet converted the data it contains.**[Find out how you can help!]3392 "")**


* 
* 
Feature | Chrome | Edge | Firefox (Gecko) | Internet Explorer | Opera | Safari (WebKit) 
Basic support | 14[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") | (Yes) | [25]3679 "Released on 2013-10-29.")(25) | 未实现 | 15[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental")<br></br>22 (unprefixed) | 6[webkit]3568 "The name of this feature is prefixed with 'webkit' as this browser considers it experimental") 
Constructor | (Yes) | ? | 未实现 | 未实现 | ? | 未实现 





## See also<a name="See_also"></a>

* [Using the Web Audio API]14975 "")



## 文档标签和贡献者
**标签：**
* [MediaStreamAudioSourceNode]14976 "")
* [Web Audio API]3830 "")

**此页面的贡献者：**[maicss]3444 "")
**最后编辑者:**[maicss]3444 ""),<time>Aug 8, 2017, 12:18:44 AM</time>


